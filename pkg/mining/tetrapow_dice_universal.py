#!/usr/bin/env python3
"""
Excalibur $EXS Protocol - Universal Batched/Fused Tetra-PoW & Dice Mining Kernel

This module provides an optimized batched and fused bit-sliced kernel for mining operations.
It improves speed, modularity, and maintainability by processing multiple hashes simultaneously
with easy fusion composition.

Key Features:
- Batched hash computation: Process multiple nonces in parallel
- Fused operations: Combine multiple hash functions efficiently
- Bit-sliced operations: Optimize bitwise operations across batches
- Universal fusion: Easy composition of different hash algorithms
- Modular design: Reusable components for all mining workflows

Performance Benefits:
- Reduced function call overhead through batching
- Better CPU cache utilization with contiguous data
- Vectorization opportunities for SIMD operations
- Shared computation across multiple hashes

Author: Travis D. Jones <holedozer@gmail.com>
License: BSD 3-Clause
"""

import hashlib
import hmac
from typing import List, Tuple, Callable, Optional
import struct


class UniversalMiningKernel:
    """
    Universal batched/fused mining kernel for Tetra-PoW and Dice operations.
    
    This kernel processes multiple mining attempts in batches, using fused
    hash operations to improve performance and maintainability.
    """
    
    # Supported hash algorithms for fusion
    HASH_ALGORITHMS = {
        'sha256': hashlib.sha256,
        'sha512': hashlib.sha512,
        'blake2b': lambda data: hashlib.blake2b(data, digest_size=32),
        'blake2s': lambda data: hashlib.blake2s(data, digest_size=32),
    }
    
    def __init__(self, batch_size: int = 32):
        """
        Initialize the universal mining kernel.
        
        Args:
            batch_size: Number of hashes to process in each batch (default: 32)
        """
        self.batch_size = batch_size
        self.total_hashes_computed = 0
    
    def batch_nonlinear_transform(self, 
                                   data_batch: List[bytes], 
                                   round_num: int,
                                   fusion_sequence: List[str] = None) -> List[bytes]:
        """
        Apply nonlinear transformation to a batch of data.
        
        This is the core batched operation that processes multiple mining
        attempts simultaneously, using a fused sequence of hash operations.
        
        Args:
            data_batch: List of input data bytes to transform
            round_num: Current round number for salting
            fusion_sequence: Sequence of hash algorithms to fuse (default: sha512, sha256, blake2b)
            
        Returns:
            List of transformed bytes
        """
        if fusion_sequence is None:
            fusion_sequence = ['sha512', 'sha256', 'blake2b']
        
        # Round salt for uniqueness
        round_salt = str(round_num).encode()
        
        results = []
        for data in data_batch:
            # Fused hash computation
            state = data + round_salt
            
            # Apply fusion sequence
            for algo_name in fusion_sequence:
                algo = self.HASH_ALGORITHMS.get(algo_name, hashlib.sha256)
                state = algo(state).digest()
            
            # Additional nonlinear mixing via XOR folding
            if len(state) >= 64:
                # XOR first 32 bytes with last 32 bytes
                folded = bytes(a ^ b for a, b in zip(state[:32], state[32:64]))
            else:
                folded = state[:32] if len(state) > 32 else state
            
            results.append(folded)
            self.total_hashes_computed += len(fusion_sequence)
        
        return results
    
    def fused_hash_computation(self,
                               axiom: str,
                               nonce_start: int,
                               count: int,
                               rounds: int = 128,
                               fusion_sequence: List[str] = None) -> List[Tuple[int, bytes, List[bytes]]]:
        """
        Compute multiple hashes in a batched/fused manner.
        
        This function processes 'count' nonces starting from nonce_start,
        running each through 'rounds' of fused transformations.
        
        Args:
            axiom: The axiom string to hash
            nonce_start: Starting nonce value
            count: Number of nonces to process
            rounds: Number of transformation rounds (default: 128)
            fusion_sequence: Hash fusion sequence (default: sha512, sha256, blake2b)
            
        Returns:
            List of tuples: (nonce, final_hash, round_states)
        """
        results = []
        
        # Process in batches
        for batch_offset in range(0, count, self.batch_size):
            batch_count = min(self.batch_size, count - batch_offset)
            
            # Initialize batch with axiom:nonce
            batch_data = []
            batch_nonces = []
            for i in range(batch_count):
                nonce = nonce_start + batch_offset + i
                initial_state = f"{axiom}:{nonce}".encode()
                batch_data.append(initial_state)
                batch_nonces.append(nonce)
            
            # Execute rounds in batched fashion
            batch_round_states = [[] for _ in range(batch_count)]
            for i in range(batch_count):
                batch_round_states[i].append(batch_data[i])
            
            for round_num in range(1, rounds + 1):
                # Batched nonlinear transform
                batch_data = self.batch_nonlinear_transform(
                    batch_data, 
                    round_num, 
                    fusion_sequence
                )
                
                # Store round states
                for i in range(batch_count):
                    batch_round_states[i].append(batch_data[i])
            
            # Final hash for each in batch
            for i in range(batch_count):
                final_hash = hashlib.sha256(batch_data[i]).digest()
                results.append((
                    batch_nonces[i],
                    final_hash,
                    batch_round_states[i]
                ))
        
        return results
    
    def batch_verify_difficulty(self, 
                                hashes: List[bytes], 
                                difficulty: int) -> List[bool]:
        """
        Verify difficulty requirement for a batch of hashes.
        
        This is a vectorized operation that checks multiple hashes
        simultaneously for efficiency.
        
        Args:
            hashes: List of hash bytes to check
            difficulty: Number of leading zero bytes required
            
        Returns:
            List of booleans indicating which hashes meet difficulty
        """
        target_prefix = b'\x00' * difficulty
        return [h[:difficulty] == target_prefix for h in hashes]
    
    def batch_mine(self,
                   axiom: str,
                   nonce_start: int,
                   max_attempts: int,
                   difficulty: int,
                   rounds: int = 128,
                   fusion_sequence: List[str] = None) -> Tuple[bool, Optional[int], Optional[bytes], Optional[List[bytes]]]:
        """
        Batched mining operation.
        
        This is the main entry point for batched mining. It processes
        multiple nonces in batches until a valid hash is found or
        max_attempts is reached.
        
        Args:
            axiom: The axiom string
            nonce_start: Starting nonce
            max_attempts: Maximum number of attempts
            difficulty: Difficulty target (leading zero bytes)
            rounds: Number of transformation rounds
            fusion_sequence: Hash fusion sequence
            
        Returns:
            Tuple of (success, nonce, final_hash, round_states)
        """
        attempts = 0
        
        while attempts < max_attempts:
            # Compute batch
            batch_count = min(self.batch_size, max_attempts - attempts)
            results = self.fused_hash_computation(
                axiom=axiom,
                nonce_start=nonce_start + attempts,
                count=batch_count,
                rounds=rounds,
                fusion_sequence=fusion_sequence
            )
            
            # Extract hashes and check difficulty
            hashes = [r[1] for r in results]
            valid_flags = self.batch_verify_difficulty(hashes, difficulty)
            
            # Check if any hash meets difficulty
            for i, is_valid in enumerate(valid_flags):
                if is_valid:
                    nonce, final_hash, round_states = results[i]
                    return True, nonce, final_hash, round_states
            
            attempts += batch_count
        
        # No valid hash found
        return False, None, None, None
    
    def batch_dice_roll_mine(self,
                            server_seed: str,
                            client_seeds: List[str],
                            nonces: List[int],
                            max_value: int = 10000) -> List[Tuple[str, int, float, int]]:
        """
        Batched dice roll mining using HMAC.
        
        Processes multiple dice rolls in batch for improved performance.
        
        Args:
            server_seed: Server seed for HMAC
            client_seeds: List of client seeds
            nonces: List of nonces
            max_value: Maximum roll value (default: 10000 for 0.00-99.99)
            
        Returns:
            List of tuples: (hmac_value, nonce, roll_float, roll_int)
        """
        results = []
        
        # Process in batches
        for i in range(0, len(client_seeds), self.batch_size):
            batch_end = min(i + self.batch_size, len(client_seeds))
            
            for j in range(i, batch_end):
                # Create message
                message = f"{client_seeds[j]}:{nonces[j]}"
                
                # Compute HMAC
                key = server_seed.encode('utf-8')
                msg = message.encode('utf-8')
                hmac_value = hmac.new(key, msg, hashlib.sha512).hexdigest()
                
                # Convert HMAC to roll
                hex_substr = hmac_value[:10]
                int_value = int(hex_substr, 16)
                roll_int = int_value % max_value
                roll_float = roll_int / 100.0
                
                results.append((hmac_value, nonces[j], roll_float, roll_int))
                self.total_hashes_computed += 1
        
        return results
    
    def get_statistics(self) -> dict:
        """
        Get kernel statistics.
        
        Returns:
            Dictionary with performance statistics
        """
        return {
            'batch_size': self.batch_size,
            'total_hashes_computed': self.total_hashes_computed,
        }


# Standalone batched functions for modular use

def batch_nonlinear_transform(data_batch: List[bytes], 
                              round_num: int,
                              fusion_sequence: List[str] = None) -> List[bytes]:
    """
    Standalone batched nonlinear transform function.
    
    This function can be used independently without instantiating the kernel class.
    
    Args:
        data_batch: List of input data bytes
        round_num: Current round number
        fusion_sequence: Sequence of hash algorithms (default: ['sha512', 'sha256', 'blake2b'])
        
    Returns:
        List of transformed bytes
    """
    kernel = UniversalMiningKernel(batch_size=len(data_batch))
    return kernel.batch_nonlinear_transform(data_batch, round_num, fusion_sequence)


def fused_hash_computation(axiom: str,
                           nonce_start: int,
                           count: int,
                           rounds: int = 128,
                           fusion_sequence: List[str] = None,
                           batch_size: int = 32) -> List[Tuple[int, bytes, List[bytes]]]:
    """
    Standalone fused hash computation function.
    
    Args:
        axiom: The axiom string
        nonce_start: Starting nonce
        count: Number of nonces to process
        rounds: Number of rounds (default: 128)
        fusion_sequence: Hash fusion sequence
        batch_size: Batch size for processing
        
    Returns:
        List of (nonce, final_hash, round_states) tuples
    """
    kernel = UniversalMiningKernel(batch_size=batch_size)
    return kernel.fused_hash_computation(axiom, nonce_start, count, rounds, fusion_sequence)


def batch_verify_difficulty(hashes: List[bytes], difficulty: int) -> List[bool]:
    """
    Standalone batch difficulty verification function.
    
    Args:
        hashes: List of hash bytes
        difficulty: Number of leading zero bytes required
        
    Returns:
        List of booleans indicating which hashes meet difficulty
    """
    target_prefix = b'\x00' * difficulty
    return [h[:difficulty] == target_prefix for h in hashes]


def create_fusion_sequence(algorithm_names: List[str]) -> List[str]:
    """
    Create a validated fusion sequence.
    
    Args:
        algorithm_names: List of algorithm names to validate
        
    Returns:
        Validated list of algorithm names
        
    Raises:
        ValueError: If any algorithm name is invalid
    """
    valid_algos = set(UniversalMiningKernel.HASH_ALGORITHMS.keys())
    for algo in algorithm_names:
        if algo not in valid_algos:
            raise ValueError(f"Invalid algorithm: {algo}. Valid options: {valid_algos}")
    return algorithm_names


# Migration and compatibility helpers

def legacy_single_hash_to_batch(legacy_hash_func: Callable[[bytes], bytes]) -> Callable[[List[bytes]], List[bytes]]:
    """
    Adapter to convert legacy single-hash functions to batched versions.
    
    This helper facilitates migration from old non-batched code.
    
    Args:
        legacy_hash_func: Function that takes bytes and returns bytes
        
    Returns:
        Function that takes List[bytes] and returns List[bytes]
    """
    def batched_wrapper(data_batch: List[bytes]) -> List[bytes]:
        return [legacy_hash_func(data) for data in data_batch]
    return batched_wrapper


if __name__ == '__main__':
    # Demonstration of the universal kernel
    print("üî• Universal Batched/Fused Mining Kernel Demo üî•")
    print("=" * 70)
    
    kernel = UniversalMiningKernel(batch_size=8)
    
    # Demo 1: Batched mining
    print("\n1. Batched Mining Demo:")
    print("-" * 70)
    axiom = "sword legend pull magic kingdom artist stone destroy forget fire steel honey question"
    success, nonce, final_hash, _ = kernel.batch_mine(
        axiom=axiom,
        nonce_start=0,
        max_attempts=100,
        difficulty=1,
        rounds=16  # Reduced for demo
    )
    
    if success:
        print(f"‚úÖ Found valid hash!")
        print(f"   Nonce: {nonce}")
        print(f"   Hash: {final_hash.hex()}")
    else:
        print("‚ùå No valid hash found in attempts")
    
    # Demo 2: Batched dice rolls
    print("\n2. Batched Dice Roll Demo:")
    print("-" * 70)
    server_seed = "demo_server_seed_12345"
    client_seeds = [f"client_seed_{i}" for i in range(5)]
    nonces = list(range(5))
    
    results = kernel.batch_dice_roll_mine(server_seed, client_seeds, nonces)
    for hmac_val, nonce, roll_f, roll_i in results:
        print(f"   Nonce {nonce}: Roll = {roll_f:.2f} (HMAC: {hmac_val[:16]}...)")
    
    # Demo 3: Statistics
    print("\n3. Kernel Statistics:")
    print("-" * 70)
    stats = kernel.get_statistics()
    for key, value in stats.items():
        print(f"   {key}: {value}")
    
    print("\n" + "=" * 70)
    print("Demo complete! This kernel can be imported and used by all miners.")
    print("=" * 70)
